{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cadCAD model for Gift Economies of Scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "author: raluca diugan\n",
    "\n",
    "This notebook contains the system model, the simulation setup, and initial analyses for the Gift Economies of Scale project. \n",
    "\n",
    "# Partial State Update Blocks\n",
    "The figure below contains the main components of the system model in terms of state update functions per timestep, in order of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "img = Image.open('../artifacts/geos_psubs_v.0.2.png')\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "import random\n",
    "import operator \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "\n",
    "import matplotlib.animation\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# cadCAD-specific imports\n",
    "from cadCAD import configs\n",
    "\n",
    "from cadCAD.configuration import Experiment\n",
    "from cadCAD.configuration.utils import config_sim\n",
    "\n",
    "from cadCAD.engine import ExecutionMode, ExecutionContext\n",
    "from cadCAD.engine import Executor\n",
    "\n",
    "\n",
    "# import geos-specific classes\n",
    "sys.path.append('../module')\n",
    "\n",
    "from geos import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations\n",
    "\n",
    "# analysis\n",
    "plt.rcParams['font.family'] = 'monospace'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state macros \n",
    "\n",
    "## request\n",
    "REQUEST_EXPIRED = \"expired\"\n",
    "REQUEST_SUBMITTED = \"submitted\"\n",
    "REQUEST_FULFILLED = \"fulfilled\"\n",
    "SUBREQUEST_FULFILLED = \"fulfilled\"\n",
    "\n",
    "## donation \n",
    "DONATION_SELECTED = \"selected\"\n",
    "DONATION_FINALIZED = \"finalized\"\n",
    "DONATION_SUBMITTED = \"submitted\"\n",
    "\n",
    "## solver\n",
    "SOLVER_BREAKDOWN = \"breakdown\"\n",
    "SOLVER_VALIDATION = \"validation\"\n",
    "SOLVER_MATCHMAKING = \"matchmaking\"\n",
    "\n",
    "## receipts\n",
    "RECEIPT_DONOR = \"donor\"\n",
    "RECEIPT_REQUESTOR = \"requestor\"\n",
    "\n",
    "## agents & solvers\n",
    "SOLVER_TYPES = [\"breakdown\", \"matchmaking\", \"validation\"]\n",
    "AGENT_TYPES = [\"decentralization-conscious\", \"honest\", \"rational\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## substep 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy functions\n",
    "\n",
    "def p_update_inventory_policy(params, substep, state_history, previous_state):\n",
    "    '''\n",
    "    updates agents' inventories across three dimensions:\n",
    "    1. consumption of resources\n",
    "    2. acquisition of resources\n",
    "    3. TODO inventory policy (increase/decrease idle stock of resource)\n",
    "    '''\n",
    "\n",
    "    agents = previous_state['agents']\n",
    "    inventory = previous_state['inventory']\n",
    "\n",
    "    new_agent_stocks = defaultdict(lambda: [])\n",
    "    new_inventory = defaultdict(lambda: {})\n",
    "    consumption = defaultdict(lambda: [])\n",
    "\n",
    "    # (1) consumption\n",
    "    for agent_id, agent in agents.items():\n",
    "\n",
    "        consumption_count = random.randint(0, 5)#(0, 5) # TODO system parameter\n",
    "        consumption_choices = random.sample(list(agent.inventory.stock.keys()), consumption_count)\n",
    "\n",
    "        for resource_id in consumption_choices:\n",
    "            if agent.inventory.stock[resource_id][\"quantity\"] > 0: # consume if enough stock\n",
    "                consumption_quantity = random.randint(1, agent.inventory.stock[resource_id][\"quantity\"]) # consume from quantity (i.e., in-use, not idle stock)\n",
    "                consumption[agent_id].append({\n",
    "                    \"resource_id\": resource_id,\n",
    "                    \"quantity\": consumption_quantity\n",
    "                })\n",
    "\n",
    "    # (2) external acquisition \n",
    "    for agent_id, agent in agents.items():\n",
    "\n",
    "        acquisition_count = random.randint(0, 5) # TODO system parameter\n",
    "        acquisition_choices = random.sample(list(inventory.stock.keys()), acquisition_count)\n",
    "\n",
    "        for resource_id in acquisition_choices:\n",
    "            if inventory.stock[resource_id][\"idle_stock\"] > 1:\n",
    "\n",
    "                # TODO update: right now qty cannot go to 0 (else division by zero in metrics) s.t. min qty of global stock is 1\n",
    "                # acquisition only from idle stock\n",
    "                acquisition_quantity = random.randint(1, min(inventory.stock[resource_id][\"idle_stock\"] - 1, 500)) \n",
    "\n",
    "                inventory.stock[resource_id][\"idle_stock\"] -= acquisition_quantity # local update, not applied to state\n",
    "                inventory.stock[resource_id][\"quantity\"] -= acquisition_quantity # local update, not applied to state\n",
    "            \n",
    "                new_inventory[resource_id] = {\n",
    "                    \"quantity\": inventory.stock[resource_id][\"quantity\"], \n",
    "                    \"idle_stock\": inventory.stock[resource_id][\"idle_stock\"]\n",
    "                }\n",
    "         \n",
    "                new_agent_stocks[agent_id].append({\n",
    "                    \"resource_id\": resource_id,\n",
    "                    \"quantity\": acquisition_quantity\n",
    "                })\n",
    "\n",
    "    # TODO (3) usage strategy\n",
    "\n",
    "    return {'new_agent_stocks': new_agent_stocks, 'new_inventory': new_inventory, 'consumption': consumption}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state update functions \n",
    "\n",
    "def s_update_inventory_policy(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    applies updates to agent inventories\n",
    "    '''\n",
    "\n",
    "    resources = previous_state['inventory']\n",
    "    agents_new = previous_state['agents'].copy()\n",
    "    consumption = policy_input['consumption']\n",
    "    new_agent_stocks = policy_input['new_agent_stocks']\n",
    "\n",
    "    # apply consumption\n",
    "    for agent_id, stocks in consumption.items():\n",
    "        for stock in stocks:\n",
    "            resource_id = stock[\"resource_id\"]\n",
    "            agents_new[agent_id].inventory.stock[resource_id][\"quantity\"] -= stock[\"quantity\"]\n",
    "   \n",
    "    # apply acquisition\n",
    "    for agent_id, stocks in new_agent_stocks.items():\n",
    "        for stock in stocks:\n",
    "            resource_id = stock[\"resource_id\"]\n",
    "            if resource_id in agents_new[agent_id].inventory.stock.keys():\n",
    "                agents_new[agent_id].inventory.stock[resource_id][\"quantity\"] += stock[\"quantity\"]\n",
    "            else:\n",
    "                agents_new[agent_id].inventory.stock[resource_id] = {\n",
    "                    \"resource\": resources.stock[resource_id][\"resource\"],\n",
    "                    \"quantity\": stock[\"quantity\"],\n",
    "                    \"idle_stock\": 0, \n",
    "                    \"locked\": 0\n",
    "                }\n",
    "            \n",
    "    # TODO apply inventory policy changes\n",
    "                \n",
    "    return ('agents', agents_new)\n",
    "\n",
    "def s_update_global_stocks(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    updates global stocks following acquisition\n",
    "    TODO add update based on natural resource decay\n",
    "    '''\n",
    "\n",
    "    inventory_new = previous_state['inventory'].make_copy()\n",
    "    new_inventory = policy_input['new_inventory']\n",
    "\n",
    "    for resource_id in new_inventory.keys():\n",
    "        inventory_new.stock[resource_id][\"quantity\"] = new_inventory[resource_id][\"quantity\"]\n",
    "        inventory_new.stock[resource_id][\"idle_stock\"] = new_inventory[resource_id][\"idle_stock\"]\n",
    "\n",
    "    return ('inventory', inventory_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## substep 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def get_new_index(resource, resource_id, agents, qty, requestor, donor, len_agents):\n",
    "    '''\n",
    "    calculates the expected decentralization index of a given resource\n",
    "    based on the donation decision of a potential (decentralization-conscious) donor\n",
    "    '''\n",
    "\n",
    "    if resource_id in agents[requestor].inventory.stock.keys():\n",
    "        agents[requestor].inventory.stock[resource_id][\"quantity\"] += qty\n",
    "    else:\n",
    "        agents[requestor].inventory.stock[resource_id] = {\n",
    "            \"resource\": resource,\n",
    "            \"quantity\": qty, \n",
    "            \"idle_stock\": 0, \n",
    "            \"locked\": 0\n",
    "        }\n",
    "    agents[donor].inventory.stock[resource_id][\"quantity\"] -= qty\n",
    "   \n",
    "    ci, min_c, max_c = calculate_concentration_index(resource_id, agents)\n",
    "    di = calculate_distribution_index(resource_id, agents, len_agents)\n",
    "    index = calculate_decentralization_index(di, ci)\n",
    "\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy functions\n",
    "\n",
    "def p_submit_request(params, substep, state_history, previous_state):\n",
    "    '''\n",
    "    submit request for resource\n",
    "    current implementation assigns request to solver within subeconomy (or global)\n",
    "    '''\n",
    "\n",
    "    agents = previous_state['agents']\n",
    "    requests = previous_state['requests'] \n",
    "    resources = previous_state['inventory'].stock \n",
    "\n",
    "    need_threshold = params['need_threshold']\n",
    "    solvers_by_economy = previous_state['solvers_by_economy']\n",
    "    \n",
    "    complex_requests = {}\n",
    "\n",
    "    for agent_id in agents:\n",
    "        need = np.random.normal(size=1)[0] # determine need, i.e., if request will be submitted\n",
    "\n",
    "        if need >= need_threshold:\n",
    "            \n",
    "            # prepare request data\n",
    "            request_id = \"request_\" + str(len(requests))\n",
    "\n",
    "            # randomize resource needed and quantity\n",
    "            resource_id = random.choice(list(resources.keys()))\n",
    "            quantity = np.random.randint(1, 20) # TODO system param (alternative: max resource qty at given time in system; in this case must handle concurrent requests)\n",
    "            economy_id = random.choice(agents[agent_id].economies) # send to one of the economies in which the agent belongs\n",
    "            solver_id = random.choice(solvers_by_economy[economy_id]) # pick solver for request\n",
    "            deadline = len(state_history) + random.randint(5, 20) # TODO system param\n",
    "            \n",
    "            # compile request\n",
    "            request = Request(request_id, resource_id, quantity, agent_id, [], resources[resource_id]['resource'].rtype, solver_id, deadline, economy_id)\n",
    "\n",
    "            requests[request_id] = request\n",
    "\n",
    "            # for complex requests, prepare for request breakdown in next substep\n",
    "            if request.rtype == \"complex\":\n",
    "                complex_requests[request_id] = request\n",
    "\n",
    "    return {'new_requests': requests, 'pending_requests': complex_requests}\n",
    "\n",
    "\n",
    "def p_donation_response(params, substep, state_history, previous_state):\n",
    "    '''\n",
    "    compile donation responses to requests in previous states\n",
    "    each agent queries all requests and determines whether they can donate (acc. to their inventory policy)\n",
    "    '''\n",
    "\n",
    "    agents = previous_state['agents']\n",
    "    requests = previous_state['requests']\n",
    "    donations = previous_state['donation_responses']\n",
    "    metrics = previous_state['metrics']\n",
    "\n",
    "    donation_responses = {}\n",
    "\n",
    "    for agent_id, agent in agents.items():\n",
    "\n",
    "        for request_id, request in requests.items():\n",
    "            if request.state == REQUEST_SUBMITTED: # only active requests, i.e., not fulfilled or expired\n",
    "                # check that current agent is not already donor to the same request\n",
    "                # TODO move to function\n",
    "                already_donated = False \n",
    "                for donation_id, donation in donations.items(): # TODO optimize (e.g., keep list of donors for request)\n",
    "                    if donation.request_id == request_id:\n",
    "                        if donation.donor == agent_id:\n",
    "                            already_donated = True\n",
    "\n",
    "                if not already_donated:\n",
    "\n",
    "                    # only atomic requests/subrequests (complex ones are solved through corresponding subrequests)\n",
    "                    if request.rtype == \"atomic\" or request.rtype == \"subrequest\":\n",
    "                        if agent_id != request.requestor: # exclude self-donations # TODO verify condition earlier\n",
    "                            # TODO handle the donation of the same resource in the same timestep\n",
    "                            if request.resource_id in agent.inventory.stock.keys(): # if agent holds the requested resource\n",
    "                                # TODO modularize agent behavior based on type\n",
    "                                # (a) decentralization conscious agents\n",
    "                                if agent.atype == AGENT_TYPES[0]:\n",
    "                                       \n",
    "                                    # TODO optimize\n",
    "                                    index_current = metrics['decentralization_index'][request.resource_id][\"decentralization_index\"]\n",
    "                                    total_stock = agent.inventory.stock[request.resource_id][\"quantity\"] + agent.inventory.stock[request.resource_id][\"idle_stock\"]\n",
    "\n",
    "                                    would_be_donated = min(request.quantity, total_stock)\n",
    "                                    resource = agent.inventory.stock[request.resource_id][\"resource\"]\n",
    "\n",
    "                                    # get expected index\n",
    "                                    index_new = get_new_index(resource, request.resource_id, agents, would_be_donated, request.requestor, agent_id, len(agents))\n",
    "                                    \n",
    "                                    if index_new > index_current: # strictly greater (equal is analoguous to rational behavior)\n",
    "                                        \n",
    "                                        if total_stock > 0: # if agent has anything of the requested resource (both idle or in use)\n",
    "\n",
    "                                            # prepare donation data\n",
    "                                            donation_id = \"donation_\" + str(len(donations) + len(donation_responses))\n",
    "                                            donation_quantity = min(request.quantity, total_stock) # donate from entire stock (except locked)\n",
    "                                            \n",
    "                                            if request.economy_id in agent.economies:\n",
    "                                                economy_id_from = request.economy_id\n",
    "                                                economy_id_to = request.economy_id\n",
    "                                            else: # choose solver for the donation if the donor and requesting agents are not in the same subeconomy \n",
    "                                                economy_id_to = request.economy_id\n",
    "                                                economy_id_from = agent.economies[0] # TODO randomize\n",
    "\n",
    "                                            # compile donation\n",
    "                                            donation = DonationResponse(donation_id, agent_id, request_id, donation_quantity, [], economy_id_from, economy_id_to)\n",
    "                    \n",
    "                                            donation_responses[donation_id] = donation\n",
    "\n",
    "                                    # TODO otherwise behaves like standard rational agents\n",
    "\n",
    "                                # (b) honest or rational\n",
    "                                # TODO split, rational should account for cost of donation\n",
    "                                elif agent.atype == AGENT_TYPES[1] or agent.atype == AGENT_TYPES[2]:\n",
    "                                    # always donate when sufficient stock\n",
    "                                    if agent.inventory.stock[request.resource_id][\"idle_stock\"] > 0: # if agent has anything of the requested resource\n",
    "                                \n",
    "                                        # prepare donation data\n",
    "                                        donation_id = \"donation_\" + str(len(donations) + len(donation_responses))\n",
    "                                        donation_quantity = min(request.quantity, agent.inventory.stock[request.resource_id]['idle_stock'])\n",
    "                                            \n",
    "                                        if request.economy_id in agent.economies:\n",
    "                                            economy_id_from = request.economy_id\n",
    "                                            economy_id_to = request.economy_id\n",
    "                                        else:\n",
    "                                            economy_id_to = request.economy_id\n",
    "                                            economy_id_from = agent.economies[0] # TODO can also be random\n",
    "                                    \n",
    "                                        # compile donation\n",
    "                                        donation = DonationResponse(donation_id, agent_id, request_id, donation_quantity, [], economy_id_from, economy_id_to)\n",
    "                                        \n",
    "                                        donation_responses[donation_id] = donation\n",
    "    \n",
    "    return {'pending_donations': donation_responses}\n",
    "\n",
    "\n",
    "def p_donation_receipt(params, substep, state_history, previous_state):\n",
    "    '''\n",
    "    agents submit donation receipts (as requestor/donor)\n",
    "    TODO: implement donation withdrawal/quantity alterations\n",
    "    '''\n",
    "\n",
    "    agents = previous_state['agents']\n",
    "    requests = previous_state['requests']\n",
    "    strategies = previous_state['strategies']\n",
    "    receipts = previous_state['donation_receipts']\n",
    "    \n",
    "    pending_receipts = {}\n",
    "\n",
    "    for agent_id in agents: \n",
    "        # each agent queries all strategies \n",
    "        # TODO optimize, e.g., strategy keeps list of agents\n",
    "        for request_id, strategy_array in strategies.items(): \n",
    "            # for a given strategy, check whether agent has already sent a receipt\n",
    "            receipt_sent = False\n",
    "            for past_receipt_id in agents[agent_id].receipts:\n",
    "                if receipts[past_receipt_id].request_id == request_id:\n",
    "                    receipt_sent = True\n",
    "\n",
    "            # if no receipt and the request submitted\n",
    "            # TODO check if second condition still needed\n",
    "            if receipt_sent == False and requests[request_id].state == REQUEST_SUBMITTED:\n",
    "                # for the donations in the strategy for fulfilling the respective request\n",
    "                for strategy in strategy_array:\n",
    "                    # check whether the current agent is the donor or requestor (i.e., whether the donation has been made or request submitted by current agent)\n",
    "                    if agent_id == strategy.donor or agent_id == requests[request_id].requestor:\n",
    "        \n",
    "                        # determine whether donor or requestor receipt (depends on who the agent is)\n",
    "                        rtype = \"\"\n",
    "                        if agent_id == strategy.donor: \n",
    "                            rtype = RECEIPT_DONOR\n",
    "                        \n",
    "                        # TODO: simplify logic\n",
    "                        elif agent_id == requests[request_id].requestor: \n",
    "                            rtype = RECEIPT_REQUESTOR\n",
    "                            \n",
    "                        # prepare receipt data\n",
    "                        quantity = strategy.quantity\n",
    "                        receipt_id = \"receipt_\" + str(len(receipts) + len(pending_receipts))\n",
    "                        solver_id = requests[request_id].solver_id\n",
    "                        resource_id = requests[request_id].resource_id\n",
    "\n",
    "                        # compile receipt; strategy_id is the corresponding donation id\n",
    "                        receipt = DonationReceipt(receipt_id, agent_id, request_id, rtype, solver_id, quantity, resource_id, strategy.id)\n",
    "\n",
    "                        pending_receipts[receipt_id] = receipt\n",
    "\n",
    "    return {'pending_receipts': pending_receipts}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state update functions\n",
    "\n",
    "def s_donation_response(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    add new donation responses to state\n",
    "    '''\n",
    "\n",
    "    pending_donations = policy_input['pending_donations']\n",
    "    donation_responses_new = previous_state['donation_responses'].copy()\n",
    "\n",
    "    for donation_id, donation in pending_donations.items():\n",
    "        donation_responses_new[donation_id] = donation \n",
    "    \n",
    "    return ('donation_responses', donation_responses_new)\n",
    "\n",
    "\n",
    "def s_donation_receipt(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    add new receipts to state\n",
    "    '''\n",
    "\n",
    "    new_receipts = policy_input['pending_receipts']\n",
    "    receipts_new = previous_state['donation_receipts'].copy()\n",
    "\n",
    "    for receipt_id, receipt in new_receipts.items():\n",
    "        receipts_new[receipt_id] = receipt\n",
    "\n",
    "    return ('donation_receipts', receipts_new)\n",
    "\n",
    "def s_donation_receipt_pool(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    add new receipts to receipt pool\n",
    "    '''\n",
    "\n",
    "    new_receipts = policy_input['pending_receipts']\n",
    "    receipts_new = previous_state['receipts_pool'].copy()\n",
    "    \n",
    "    for receipt_id, receipt in new_receipts.items():\n",
    "        receipts_new[receipt_id] = receipt\n",
    "\n",
    "    return ('receipts_pool', receipts_new)\n",
    "\n",
    "def s_agent_receipts(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    add new receipts to the respective agent's state\n",
    "    '''\n",
    "    \n",
    "    new_receipts = policy_input['pending_receipts']\n",
    "    agents_new = previous_state['agents'].copy()\n",
    "\n",
    "    for receipt_id, receipt in new_receipts.items():\n",
    "        agent_id = receipt.agent_id\n",
    "\n",
    "        agents_new[agent_id].receipts.append(receipt_id)\n",
    "\n",
    "    return ('agents', agents_new)\n",
    "\n",
    "def s_new_request(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    add new requests to state\n",
    "    '''\n",
    "\n",
    "    pending_requests = policy_input['new_requests']\n",
    "    requests_new = previous_state['requests'].copy()\n",
    "\n",
    "    for request_id in pending_requests.keys():\n",
    "        requests_new[request_id] = pending_requests[request_id]\n",
    "\n",
    "    return ('requests', requests_new)\n",
    "\n",
    "def s_request_pool(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    add new requests to the request pool (for request breakdown where applicable)\n",
    "    '''\n",
    "\n",
    "    pending_requests = policy_input['pending_requests']\n",
    "    request_pool_new = previous_state['requests_pool'].copy()\n",
    "\n",
    "    for request_id in pending_requests.keys():\n",
    "        request_pool_new[request_id] = pending_requests[request_id]\n",
    "\n",
    "    return ('requests_pool', request_pool_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## substep 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def build_strategy(options, required_quantity):\n",
    "    '''\n",
    "    build donation strategy given responses and the required quantity\n",
    "    TODO add solving algorithms (1), handle constraints (2), handle overdonation in multi-donation strategies (3)\n",
    "    '''\n",
    "\n",
    "    initial_quantity = required_quantity\n",
    "\n",
    "    strategy = []\n",
    "    running_sum = 0\n",
    "\n",
    "    # source: https://ioflood.com/blog/python-sort-dictionary-by-value/\n",
    "    # sort donations by qty (decreasing order (optimizes for least amount of donations))\n",
    "    quantities = dict(sorted(options.items(), key=operator.itemgetter(1), reverse=True))\n",
    "   \n",
    "    # keep selecting donations until required quantity is reached\n",
    "    for donation_id, quantity in quantities.items():\n",
    "       \n",
    "        if running_sum >= initial_quantity:\n",
    "            break\n",
    "    \n",
    "        strategy.append(donation_id)\n",
    "        running_sum += quantity\n",
    "\n",
    "    return strategy, initial_quantity - running_sum # also return the overdonated quantity\n",
    "\n",
    "\n",
    "def build_strategy_by_economy(options, request):\n",
    "    '''\n",
    "    build strategy given donation responses\n",
    "    optimize for quantity within the same subeconomy, quantity from external donations\n",
    "    TODO add delay for building strategy\n",
    "    '''\n",
    "\n",
    "    economy_requestor = request.economy_id\n",
    "    requested_quantity = request.quantity\n",
    "\n",
    "    aggregated_quantity = 0\n",
    "    candidate_donations = {}\n",
    "    other_donations = {}\n",
    "    s, s2 = [], []\n",
    "    over, over2 = 0, 0\n",
    "\n",
    "    for donation_id, donation in options.items():\n",
    "        if donation.economy_id_from == economy_requestor: # if the donation comes from within the same economy\n",
    "            aggregated_quantity += donation.quantity\n",
    "            candidate_donations[donation_id] = donation.quantity\n",
    "        else:\n",
    "            other_donations[donation_id] = donation.quantity\n",
    "\n",
    "    if aggregated_quantity >= requested_quantity: # if enough quantity for a donation within subeconomy, select candidates by descending quantity\n",
    "        \n",
    "        s, over = build_strategy(candidate_donations, request.quantity)\n",
    "        \n",
    "        return s, over\n",
    "        \n",
    "    else:   # if not sufficient donations within economy\n",
    "        remaining_quantity = requested_quantity - aggregated_quantity \n",
    "        s2, over2 = build_strategy(other_donations, remaining_quantity - over) # over has been covered already with the overdonation\n",
    "\n",
    "    for donation_id in s2:\n",
    "        s.append(donation_id)\n",
    "\n",
    "    return s, over2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy functions\n",
    "\n",
    "def p_request_breakdown(params, substep, state_history, previous_state):\n",
    "    '''\n",
    "    breaks down complex requests into subrequests according to the dependent resources (currently subrequrest qty is random and capped at main request qty)\n",
    "    TODO increase resource dependency depth\n",
    "    NOTE treatment of solvers not differentiated (all perform the same task in the same substep)\n",
    "    '''\n",
    "\n",
    "    inventory = previous_state['inventory']\n",
    "    requests_pool = previous_state['requests_pool']\n",
    "    \n",
    "    cleared = []\n",
    "    subrequests = {}\n",
    "    \n",
    "    for request_id, request in requests_pool.items():\n",
    "       \n",
    "        resource_id = request.resource_id\n",
    "        ctr = 0 # determines subrequest id\n",
    "\n",
    "        # for each dependency of the requested resource compile a new request\n",
    "        for dependency in inventory.stock[resource_id][\"resource\"].dependencies:\n",
    "\n",
    "            # prepare subrequest data\n",
    "            resource_id = dependency\n",
    "            subrequest_id = request_id + \"_\" + str(ctr)\n",
    "\n",
    "            # TODO non-random subrequest qty\n",
    "                # this would require request breakdown on the client side\n",
    "            subrequest_quantity = random.choice(range(1, request.quantity + 1))\n",
    "            \n",
    "            # compile subrequest\n",
    "            subrequest = Request(subrequest_id, resource_id, subrequest_quantity, request.requestor, [], \"subrequest\", request.solver_id, request.deadline, request.economy_id)\n",
    "            \n",
    "            # prepare to update the request's dependencies\n",
    "            request.subrequests.append(subrequest)\n",
    "\n",
    "            # prepare to update requests\n",
    "            subrequests[subrequest_id] = subrequest\n",
    "\n",
    "            ctr += 1\n",
    "\n",
    "        # keep track of processed main requests\n",
    "        cleared.append(request_id)\n",
    "\n",
    "    return {'subrequests': subrequests, 'cleared': cleared}\n",
    "\n",
    "def p_receipts_match(params, substep, state_history, previous_state):\n",
    "    '''\n",
    "    match receipts in receipts pool corresponding to the same request\n",
    "    when a complete match is available (i.e., for all subrequests/donation pairs), mark request for fulfillment\n",
    "    '''\n",
    "    \n",
    "    requests = previous_state['requests']\n",
    "    strategies = previous_state['strategies']\n",
    "    receipts = previous_state['receipts_pool']\n",
    "    \n",
    "    requests_receipts = {}\n",
    "    fulfilled_requests = []\n",
    "    donations_finalized = []\n",
    "\n",
    "    # get requestor receipts\n",
    "    for receipt_id, receipt in receipts.items():\n",
    "        if receipt.rtype == RECEIPT_REQUESTOR:\n",
    "\n",
    "            request_id = receipt.request_id\n",
    "\n",
    "            requests_receipts[request_id] = {\n",
    "                \"expected_receipts\": len(strategies[request_id]), \n",
    "                \"expected_quantity\": requests[request_id].quantity\n",
    "            }\n",
    "\n",
    "    # for each request with a requestor receipt look for matching donor receipt(s) (number and quantity)\n",
    "    # TODO optimize\n",
    "    for request_id in requests_receipts.keys():\n",
    "    \n",
    "        qty = 0\n",
    "        donors = []\n",
    "        donation_receipts_count = 0\n",
    "        pending_donations = []\n",
    "        \n",
    "        for receipt_id, receipt in receipts.items():\n",
    "            if request_id == receipt.request_id: # if matching receipt for request\n",
    "                # if receipt from donor\n",
    "                # if new donor than previous matching donor receipts\n",
    "                if receipt.rtype == RECEIPT_DONOR and receipt.agent_id not in donors:\n",
    "        \n",
    "                    donors.append(receipt.agent_id)\n",
    "                    donation_receipts_count += 1\n",
    "                    qty += receipt.quantity \n",
    "\n",
    "                    pending_donations.append(receipt.donation_id)\n",
    "\n",
    "        # if conditions for matching receipt(s) met \n",
    "        # TODO FIX qty should be equal after fix (not >=) (current implementation allowes overdonation by last donation in multi-donation strategies)\n",
    "        if donation_receipts_count == requests_receipts[request_id][\"expected_receipts\"] and qty >= requests_receipts[request_id][\"expected_quantity\"]:\n",
    "          \n",
    "            fulfilled_requests.append(request_id) # keep track of fulfilled requests\n",
    "            \n",
    "            for donation_id in pending_donations:\n",
    "                if donation_id not in donations_finalized:\n",
    "                    donations_finalized.append(donation_id)\n",
    "\n",
    "    return {'pending_requests_fulfilled': set(fulfilled_requests), 'finalized_donations': donations_finalized}\n",
    "\n",
    "def p_donation_strategies(params, substep, state_history, previous_state):\n",
    "    '''\n",
    "    compile donation strategies for requests according to corresponding donation responses\n",
    "    if individual donations do not suffice, compiles multi-donation strategies\n",
    "    TODO add multiple strategy construction methods, integrate constraints in strategy preference (e.g., urgent requests)\n",
    "    TODO optimize logic\n",
    "    '''\n",
    "\n",
    "    requests = previous_state['requests']\n",
    "    pending_donations = previous_state['donation_responses']\n",
    "\n",
    "    strategies = defaultdict(lambda: [])\n",
    "    selected_strategies = defaultdict(lambda: [])\n",
    "\n",
    "    # if no strategy for a given request\n",
    "    # collect all corresponding donations\n",
    "    for donation_id in pending_donations.keys():\n",
    "        req_id = pending_donations[donation_id].request_id\n",
    "\n",
    "        if requests[req_id].strategy_added == False: # if no existing strategy\n",
    "            strategies[req_id].append(donation_id)\n",
    "\n",
    "    # for each request for which a strategy does not exist\n",
    "    for request_id in strategies.keys():\n",
    "    \n",
    "        # check if a strategy can be assembled, i.e., the sum of existing donation quantities is sufficient\n",
    "        options = {}\n",
    "        options_by_economy = {}\n",
    "        sum_donations = 0\n",
    "\n",
    "        # sum up all donation quantities\n",
    "        for donation_id in strategies[request_id]:\n",
    "            if pending_donations[donation_id].state != DONATION_SELECTED:\n",
    "\n",
    "                options[donation_id] = pending_donations[donation_id].quantity\n",
    "                options_by_economy[donation_id] = pending_donations[donation_id]\n",
    "                sum_donations += pending_donations[donation_id].quantity\n",
    "        \n",
    "        if sum_donations >= requests[request_id].quantity:\n",
    "    \n",
    "            # prioritize by economy\n",
    "            # TODO handle the excess donation (over_by_economy)\n",
    "            solution_by_economy, over_by_economy = build_strategy_by_economy(options_by_economy, requests[request_id])\n",
    "                        \n",
    "            for donation_id in solution_by_economy: #s:\n",
    "                selected_strategies[request_id].append(pending_donations[donation_id])\n",
    "    \n",
    "    return {'pending_strategies': selected_strategies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state update functions\n",
    "\n",
    "def s_donation_strategies(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    apply new donation strategies if no strategy already exists\n",
    "    TODO optimize (in policy) to only construct/apply new strategies\n",
    "    '''\n",
    "\n",
    "    strategies_new = previous_state['strategies'].copy()\n",
    "    new_strategies = policy_input['pending_strategies']\n",
    "    \n",
    "    for request_id, donations in new_strategies.items():\n",
    "        if request_id not in strategies_new.keys():\n",
    "            strategies_new[request_id] = donations \n",
    "        \n",
    "    return ('strategies', strategies_new)\n",
    "\n",
    "def s_donation_responses_old(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    update donation reponse state when selected for strategies\n",
    "    '''\n",
    "\n",
    "    strategies = policy_input['pending_strategies']\n",
    "    donation_responses_new = previous_state['donation_responses'].copy()\n",
    "    \n",
    "    # mark donations selected in strategies\n",
    "    for request_id, donations in strategies.items():\n",
    "        for donation in donations:\n",
    "            donation_responses_new[donation.id].state = DONATION_SELECTED\n",
    "    \n",
    "    return ('donation_responses', donation_responses_new)\n",
    "\n",
    "\n",
    "def s_lock_quantities(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    update agents' inventories to reflect quantities locked in strategies\n",
    "    TODO simplify logic\n",
    "    '''\n",
    "\n",
    "    donors = previous_state['agents']\n",
    "    requests = previous_state['requests']\n",
    "    agents_new = previous_state['agents'].copy()\n",
    "    strategies = policy_input['pending_strategies']\n",
    "\n",
    "    for request_id, donations in strategies.items():\n",
    "        for donation in donations: \n",
    "            request_id = donation.request_id\n",
    "            resource_id = requests[request_id].resource_id\n",
    "\n",
    "            # separately tackle stock updates for decentralization conscious agents\n",
    "            if donors[donation.donor].atype == AGENT_TYPES[0]:\n",
    "                # lock the full amount\n",
    "                agents_new[donation.donor].inventory.stock[resource_id][\"locked\"] += donation.quantity # update locked stock\n",
    "\n",
    "                # decrease idle_stock\n",
    "                decrease_idle = min(donation.quantity, donors[donation.donor].inventory.stock[resource_id][\"idle_stock\"])\n",
    "                agents_new[donation.donor].inventory.stock[resource_id][\"idle_stock\"] -= decrease_idle\n",
    "\n",
    "                optional_remainder = donation.quantity - decrease_idle\n",
    "                # also remove from in use stock\n",
    "                if optional_remainder > 0:\n",
    "                    agents_new[donation.donor].inventory.stock[resource_id][\"quantity\"] -= optional_remainder\n",
    "\n",
    "            else:\n",
    "                agents_new[donation.donor].inventory.stock[resource_id][\"locked\"] += donation.quantity # update locked stock\n",
    "                agents_new[donation.donor].inventory.stock[resource_id][\"idle_stock\"] -= donation.quantity # decrease amount of available stock\n",
    "\n",
    "    return ('agents', agents_new)\n",
    "\n",
    "# TODO rename to reflect dual functionality\n",
    "def s_request_breakdown(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    updates requests (1) adds new subrequests (2) marks fulfilled requests (3) marks requests for which strategies exist\n",
    "    TODO update expired requests (must implement request deadlines)\n",
    "    '''\n",
    "    \n",
    "    subrequests = policy_input['subrequests']\n",
    "    requests_new = previous_state['requests'].copy()\n",
    "    strategies_added = policy_input['pending_strategies']\n",
    "    pending_requests_fulfilled = policy_input['pending_requests_fulfilled']\n",
    "\n",
    "    # add new requests (subrequests)\n",
    "    for request_id in subrequests.keys():\n",
    "        requests_new[request_id] = subrequests[request_id]\n",
    "\n",
    "    # updated fulfilled requests\n",
    "    for request_id in pending_requests_fulfilled:\n",
    "        requests_new[request_id].state = REQUEST_FULFILLED\n",
    "\n",
    "    # update requests with strategies\n",
    "    for request_id in strategies_added.keys():\n",
    "        requests_new[request_id].strategy_added = True\n",
    "\n",
    "    return ('requests', requests_new)\n",
    "\n",
    "def s_requests_fulfilled_pool(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    updates the fulfilled requests pool to support stock updates in the next substep\n",
    "    TODO simplify logic\n",
    "    '''\n",
    "\n",
    "    requests = previous_state['requests']\n",
    "    requests_pool_new = previous_state['requests_fulfilled_pool'].copy()\n",
    "    pending_requests_fulfilled = policy_input['pending_requests_fulfilled']\n",
    "\n",
    "    for request_id in pending_requests_fulfilled:\n",
    "        requests_pool_new[request_id] = requests[request_id]\n",
    "\n",
    "    return ('requests_fulfilled_pool', requests_pool_new)\n",
    "\n",
    "def s_receipts_pool_clear(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    remove matched receipts\n",
    "    TODO integrate present logic in receipts matching\n",
    "    '''\n",
    "\n",
    "    receipts_pool_new = previous_state['receipts_pool'].copy()\n",
    "    pending_requests_fulfilled = policy_input['pending_requests_fulfilled']\n",
    "\n",
    "    removable_receipts = []\n",
    "\n",
    "    # find all obsolete receipts (that have been employed to fulfill a request)\n",
    "    for request_id in pending_requests_fulfilled:\n",
    "        for receipt_id, receipt in receipts_pool_new.items():\n",
    "            if receipt.request_id == request_id:\n",
    "                removable_receipts.append(receipt_id)\n",
    "                \n",
    "    # remove receipts from pool\n",
    "    for receipt_id in removable_receipts:    \n",
    "        del receipts_pool_new[receipt_id]\n",
    "\n",
    "    return ('receipts_pool', receipts_pool_new)\n",
    "\n",
    "def s_clear_pool(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    clear complex requests pool\n",
    "    '''\n",
    "\n",
    "    cleared_requests =  policy_input['cleared']\n",
    "    requests_pool_new = previous_state['requests_pool'].copy()\n",
    "    \n",
    "    for request_id in cleared_requests:\n",
    "        del requests_pool_new[request_id]\n",
    "\n",
    "    return ('requests_pool', requests_pool_new)\n",
    "\n",
    "def s_finalized_donations_pool(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    updated the pool of completed donations to support update stock logic\n",
    "    TODO simplify process\n",
    "    '''\n",
    "\n",
    "    finalized_donations = policy_input['finalized_donations']\n",
    "    finalized_donations_pool_new = previous_state['finalized_donations_pool'].copy()\n",
    "\n",
    "    for donation_id in finalized_donations:\n",
    "        finalized_donations_pool_new.append(donation_id)\n",
    "\n",
    "    return ('finalized_donations_pool', finalized_donations_pool_new)\n",
    "\n",
    "\n",
    "def s_finalize_donations(params, substep, state_history, previous_state, policy_input):\n",
    "    ''' \n",
    "    update state of finalized donation responses\n",
    "    '''\n",
    "\n",
    "    donation_responses_new = previous_state['donation_responses'].copy()\n",
    "    finalized_donations = policy_input['finalized_donations']\n",
    "\n",
    "    for donation_id in finalized_donations:\n",
    "        donation_responses_new[donation_id].state = DONATION_FINALIZED\n",
    "\n",
    "    return ('donation_responses', donation_responses_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## substep 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy functions\n",
    "\n",
    "def p_update_stocks(params, substep, state_history, previous_state):\n",
    "    '''\n",
    "    updates agents' inventories according to fulfilled requests (inc. if requestor, dec. if donor)\n",
    "    TODO integrate 'donations' from system stock\n",
    "    '''\n",
    "\n",
    "    receipts = previous_state['donation_receipts']\n",
    "    fulfilled_requests = previous_state['requests_fulfilled_pool']\n",
    "\n",
    "    new_agents_stocks = defaultdict(lambda: [])\n",
    "    \n",
    "    # handles situations where an agent both donates and receives the same resource within the same timestep\n",
    "    # for each fulfilled request, mark decrease (donor) or increase (requestor)\n",
    "    # determine agent based on receipt rtype\n",
    "    for request_id in fulfilled_requests:\n",
    "        for receipt_id, receipt in receipts.items():\n",
    "            if receipt.request_id == request_id:\n",
    "\n",
    "                if receipt.rtype == RECEIPT_DONOR:\n",
    "                    new_agents_stocks[receipt.agent_id].append({\"resource_id\": receipt.resource_id, \"quantity\": receipt.quantity, \"operation\": \"decrease\"})\n",
    "                    \n",
    "                elif receipt.rtype == RECEIPT_REQUESTOR:\n",
    "                    new_agents_stocks[receipt.agent_id].append({\"resource_id\": receipt.resource_id, \"quantity\": receipt.quantity, \"operation\": \"increase\"})\n",
    "\n",
    "    return {'new_agents_stocks': new_agents_stocks} \n",
    "\n",
    "def p_request_expired(params, substep, state_history, previous_state):\n",
    "    '''\n",
    "    identify expired requests based on state id\n",
    "    '''\n",
    "\n",
    "    st = len(state_history)\n",
    "    requests = previous_state['requests']\n",
    "    expired_requests = []\n",
    "\n",
    "    for request_id, request in requests.items():\n",
    "        if st > request.deadline and request.state == REQUEST_SUBMITTED: # exclude fulfilled requests\n",
    "            \n",
    "            expired_requests.append(request_id)\n",
    "\n",
    "    return {'expired_requests': expired_requests}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state update functions \n",
    "\n",
    "def s_update_stocks(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    apply changes to agents' stocks\n",
    "    '''\n",
    "\n",
    "    resources = previous_state['inventory']\n",
    "    agents_new = previous_state['agents'].copy()\n",
    "    new_agents_stocks = policy_input['new_agents_stocks']\n",
    "    \n",
    "    # for all changes to agents' stocks, apply as decrease/increase\n",
    "    for agent_id, new_stocks in new_agents_stocks.items():\n",
    "        # TODO verify correctness of decentralization conscious stock updates\n",
    "        for new_stock in new_stocks:\n",
    "\n",
    "            if new_stock[\"operation\"] == \"decrease\": # decrease qty, idle_stock, and remove lock for donated qty\n",
    "                agents_new[agent_id].inventory.stock[new_stock[\"resource_id\"]][\"quantity\"] -= new_stock[\"quantity\"]\n",
    "                agents_new[agent_id].inventory.stock[new_stock[\"resource_id\"]][\"idle_stock\"] -= new_stock[\"quantity\"]\n",
    "                agents_new[agent_id].inventory.stock[new_stock[\"resource_id\"]][\"locked\"] -= new_stock[\"quantity\"]\n",
    "\n",
    "            elif new_stock[\"operation\"] == \"increase\": # increase qty or add as new resource\n",
    "\n",
    "                if new_stock[\"resource_id\"] not in agents_new[agent_id].inventory.stock.keys(): # if new resource\n",
    "\n",
    "                    resource_id = new_stock[\"resource_id\"]\n",
    "\n",
    "                    agents_new[agent_id].inventory.stock[new_stock[\"resource_id\"]] = {\n",
    "                        \"resource\": resources.stock[resource_id][\"resource\"],\n",
    "                        \"quantity\": new_stock[\"quantity\"], # received qty\n",
    "                        \"idle_stock\": 0,\n",
    "                        \"locked\": 0 # no donation pending\n",
    "                        }\n",
    "                    \n",
    "                else: # if resource already in inventory, update qty; no change to idle stock/locked qty\n",
    "                    agents_new[agent_id].inventory.stock[new_stock[\"resource_id\"]][\"quantity\"] += new_stock[\"quantity\"]\n",
    "\n",
    "    return ('agents', agents_new)\n",
    "\n",
    "def s_clear_requests_fulfilled_pool(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    clear pool of fulfilled requests\n",
    "    '''\n",
    "\n",
    "    requests_fulfilled = previous_state['requests_fulfilled_pool']\n",
    "    requests_fulfilled_pool_new = previous_state['requests_fulfilled_pool'].copy()\n",
    "    \n",
    "    for request_id in requests_fulfilled:\n",
    "        del requests_fulfilled_pool_new[request_id]\n",
    "\n",
    "    return ('requests_fulfilled_pool', requests_fulfilled_pool_new)\n",
    "\n",
    "\n",
    "def s_request_expired(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    update state of expired requests\n",
    "    '''\n",
    "\n",
    "    requests_expired = policy_input['expired_requests']\n",
    "    requests_new = previous_state['requests'].copy()\n",
    "\n",
    "    for request_id in requests_expired:\n",
    "        requests_new[request_id].state = REQUEST_EXPIRED\n",
    "\n",
    "    return ('requests', requests_new)\n",
    "\n",
    "def s_clear_finalized_donations_pool(params, substep, state_history, previous_state, policy_input):\n",
    "    ''' \n",
    "    NOTE pools cannot be cleared in the same substep\n",
    "    TODO simplify\n",
    "    '''\n",
    "\n",
    "    return ('finalized_donations_pool', [])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## substep 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "# TODO move to library\n",
    "\n",
    "def calculate_average_request_fulfillment_latency(state_history):\n",
    "    '''\n",
    "    compute average latency of fulfilling requests\n",
    "    TODO simplify\n",
    "    '''\n",
    "  \n",
    "    latencies = []\n",
    "    latency_by_request_fulfilled = {}\n",
    "\n",
    "    for state_id in range(len(state_history)): # for each state\n",
    "        for substep_id in range(len(state_history[state_id])):\n",
    "            for request_id, request in state_history[state_id][substep_id]['requests'].items(): # for each request\n",
    "\n",
    "                if request_id not in latency_by_request_fulfilled: # (for each request not accounted for yet)\n",
    "\n",
    "                    latency_by_request_fulfilled[request_id] = {\n",
    "                        \"submitted\": float(state_id), # state when submitted\n",
    "                        \"fulfilled\": -1,\n",
    "                    }\n",
    "                \n",
    "                # mark when request fulfilled\n",
    "                if request.state == REQUEST_FULFILLED and latency_by_request_fulfilled[request_id][\"fulfilled\"] == -1:\n",
    "                    latency_by_request_fulfilled[request_id][\"fulfilled\"] = float(state_id) \n",
    "\n",
    "    # find latency per request\n",
    "    for request_id in latency_by_request_fulfilled.keys():\n",
    "        if latency_by_request_fulfilled[request_id][\"fulfilled\"] > -1:\n",
    "\n",
    "            latency = latency_by_request_fulfilled[request_id][\"fulfilled\"] - latency_by_request_fulfilled[request_id][\"submitted\"]\n",
    "            latencies.append(latency)\n",
    "\n",
    "    # if no requests fulfilled (for initial state)\n",
    "    if len(latencies) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return round(sum(latencies) / len(latencies), 2) # avg latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy update functions\n",
    "\n",
    "def p_update_metrics(params, substep, state_history, previous_state):\n",
    "    '''\n",
    "    compute latest metrics\n",
    "    '''\n",
    "\n",
    "    agents = previous_state['agents']\n",
    "    requests = previous_state['requests']\n",
    "    resources = previous_state['inventory']\n",
    "    \n",
    "    pending_metrics = {}\n",
    "    requests_fulfilled = 0\n",
    "    decentralization_indices = defaultdict(lambda: {})\n",
    "\n",
    "    # requests fulfilled\n",
    "    for request_id, request in requests.items():\n",
    "        if request.state == REQUEST_FULFILLED:\n",
    "            requests_fulfilled += 1\n",
    "    \n",
    "    # set new throughput\n",
    "    pending_metrics['throughput'] = requests_fulfilled\n",
    "   \n",
    "    # compute new idling capacities\n",
    "    idling_capacity_overall, idling_capacity_by_resource = calculate_cumulative_idling_capacity(previous_state['inventory'], previous_state['agents'])\n",
    "\n",
    "    # set new idling capacities\n",
    "    pending_metrics['cumulative_idling_capacity'] = idling_capacity_overall\n",
    "    pending_metrics['cumulative_idling_capacity_by_resource'] = idling_capacity_by_resource\n",
    "\n",
    "    # compute and set latency\n",
    "    pending_metrics['latency'] = calculate_average_request_fulfillment_latency(state_history)\n",
    "  \n",
    "    for resource_id in inventory.stock.keys():\n",
    "\n",
    "        decentralization_indices[resource_id] = {}\n",
    "        ci, min_c, max_c = calculate_concentration_index(resource_id, agents)\n",
    "        di = calculate_distribution_index(resource_id, agents, len(agents))\n",
    "        decentralization_indices[resource_id][\"concentration_index\"] = ci\n",
    "        decentralization_indices[resource_id][\"distribution_index\"] = di\n",
    "        decentralization_indices[resource_id][\"decentralization_index\"]= calculate_decentralization_index(di, ci)\n",
    "        decentralization_indices[resource_id][\"min_c\"] = round(min_c, 2)\n",
    "        decentralization_indices[resource_id][\"max_c\"] = round(max_c, 2)\n",
    "\n",
    "    # set decentralization indices\n",
    "    pending_metrics['decentralization_index'] = decentralization_indices\n",
    "\n",
    "    return {'pending_metrics': pending_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state update functions \n",
    "\n",
    "def s_update_metrics(params, substep, state_history, previous_state, policy_input):\n",
    "    '''\n",
    "    apply updates to metrics\n",
    "    '''\n",
    "\n",
    "    metrics_new = previous_state['metrics'].copy()\n",
    "    pending_metrics = policy_input['pending_metrics']\n",
    "   \n",
    "    for metric_id in pending_metrics.keys():\n",
    "        metrics_new[metric_id] = pending_metrics[metric_id]\n",
    "\n",
    "    return ('metrics', metrics_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PSUBs = [\n",
    "    {\n",
    "        \"policies\": {\n",
    "            'p_update_inventory_policy': p_update_inventory_policy,\n",
    "        },\n",
    "        \"variables\": {\n",
    "            'agents': s_update_inventory_policy, \n",
    "            'inventory': s_update_global_stocks,\n",
    "        }\n",
    "    }, # substep 1\n",
    "    {\n",
    "        \"policies\": {\n",
    "            'p_submit_request': p_submit_request,\n",
    "            'p_donation_response': p_donation_response,\n",
    "            'p_donation_receipt': p_donation_receipt,\n",
    "            \n",
    "        },\n",
    "        \"variables\": {\n",
    "            'requests': s_new_request,\n",
    "            'requests_pool': s_request_pool,\n",
    "            'donation_responses': s_donation_response,\n",
    "            'donation_receipts': s_donation_receipt, \n",
    "            'receipts_pool': s_donation_receipt_pool,\n",
    "            'agents': s_agent_receipts,\n",
    "        }\n",
    "    }, # substep 2\n",
    "    {\n",
    "        \"policies\": {\n",
    "            'p_request_breakdown': p_request_breakdown,\n",
    "            'p_donation_strategies': p_donation_strategies,\n",
    "            'p_receipts_match': p_receipts_match,\n",
    "        },\n",
    "        \"variables\": {\n",
    "            'requests': s_request_breakdown,\n",
    "            'requests_pool': s_clear_pool,\n",
    "            'strategies': s_donation_strategies,\n",
    "            'donation_responses': s_donation_responses_old,\n",
    "            'receipts_pool': s_receipts_pool_clear,\n",
    "            'requests_fulfilled_pool': s_requests_fulfilled_pool,\n",
    "            'agents': s_lock_quantities,\n",
    "            'finalized_donations_pool': s_finalized_donations_pool,\n",
    "            'donation_responses': s_finalize_donations,\n",
    "        }\n",
    "    }, # substep 3\n",
    "    {\n",
    "        \"policies\": {\n",
    "            'p_update_stocks': p_update_stocks,\n",
    "            'p_request_expired': p_request_expired,\n",
    "        },\n",
    "        \"variables\": {\n",
    "            'requests': s_request_expired,\n",
    "            'agents': s_update_stocks,\n",
    "            'requests_fulfilled_pool': s_clear_requests_fulfilled_pool,\n",
    "            'finalized_donations_pool': s_clear_finalized_donations_pool,\n",
    "        }\n",
    "    }, # substep 4\n",
    "    {\n",
    "        \"policies\": {\n",
    "            'p_update_metrics': p_update_metrics,\n",
    "        },\n",
    "        \"variables\": {\n",
    "            'metrics': s_update_metrics\n",
    "        }\n",
    "    }, # substep 5\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialization data\n",
    "\n",
    "MAX_QTY_RESOURCES = 20000\n",
    "COUNT_RESOURCES = 100\n",
    "\n",
    "initial_state_params = {\n",
    "    'need_threshold': [0.8],\n",
    "    'count_economies': 5,\n",
    "    'count_agents': 20,\n",
    "    'count_solvers': 5,\n",
    "    'count_resources': COUNT_RESOURCES, \n",
    "    'count_resource_dependencies': 3,\n",
    "    'max_qty_resources': MAX_QTY_RESOURCES,\n",
    "    'min_qty_resources': 50,\n",
    "    'max_resource_count_agent': 20,\n",
    "    'min_resource_count_agent': 5,\n",
    "    'max_qty_resources_agent': 10,\n",
    "    'count_resources_1': int(0.3 * COUNT_RESOURCES),\n",
    "    'count_resources_2': int(0.7 * COUNT_RESOURCES),\n",
    "    'agent_types_probabilities': [0.5, 0.4, 0.1], # decentralization-conscious, honest, rational\n",
    "    'solver_types_probabilities': [0.3, 0.7], # whether the solver is global\n",
    "    'resource_dependency_probabilities': [0.7, 0.3] #\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize variables\n",
    "\n",
    "economies = [\"econ_\" + str(i) for i in range(initial_state_params['count_economies'])]\n",
    "\n",
    "agents = init_agents(economies, initial_state_params['count_agents'], initial_state_params['agent_types_probabilities'])\n",
    "solvers = init_solvers(economies, initial_state_params['count_solvers'], initial_state_params['solver_types_probabilities'])\n",
    "\n",
    "inventory = Inventory()\n",
    "resources = init_resources(initial_state_params['count_resources_1'], initial_state_params['count_resources_2'], initial_state_params['resource_dependency_probabilities'])\n",
    "\n",
    "for resource_id, resource in resources.items():\n",
    "    quantity = random.randint(initial_state_params['min_qty_resources'], initial_state_params['max_qty_resources'])\n",
    "    inventory.add_resource(resource_id, resource, quantity, quantity) # full stock availability\n",
    "\n",
    "\n",
    "agents, inventory = distribute_inventory(agents, initial_state_params['min_resource_count_agent'], initial_state_params['max_resource_count_agent'], inventory)\n",
    "idling_capacity_overall, idling_capacity_by_resource = calculate_cumulative_idling_capacity(inventory, agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO wrap as function (also apply to metrics update policy)\n",
    "                                          \n",
    "decentralization_indices = defaultdict(lambda: {})\n",
    "\n",
    "for resource_id in inventory.stock.keys():\n",
    "    decentralization_indices[resource_id] = {}\n",
    "    (ci, min_c, max_c) = calculate_concentration_index(resource_id, agents)\n",
    "    di = calculate_distribution_index(resource_id, agents, initial_state_params['count_agents'])\n",
    "    decentralization_indices[resource_id][\"concentration_index\"] = ci\n",
    "    decentralization_indices[resource_id][\"distribution_index\"] = di\n",
    "    decentralization_indices[resource_id][\"decentralization_index\"]= calculate_decentralization_index(di, ci)\n",
    "    decentralization_indices[resource_id][\"min_c\"] = round(min_c, 2)\n",
    "    decentralization_indices[resource_id][\"max_c\"] = round(max_c, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: wrap as function\n",
    "\n",
    "solvers_by_economy = defaultdict(lambda: [])\n",
    "\n",
    "for economy in economies:\n",
    "    for solver_id, solver in solvers.items():\n",
    "        if economy in solver.economies:\n",
    "            solvers_by_economy[economy].append(solver_id)\n",
    "        if 'global' in solver.economies:\n",
    "            if solver_id not in solvers_by_economy['global']:\n",
    "                solvers_by_economy['global'].append(solver_id)\n",
    "    solvers_by_economy[economy] = list(set(solvers_by_economy[economy]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial state\n",
    "\n",
    "initial_state = {\n",
    "    'requests': {}, # resource requests by their id\n",
    "    'donation_responses': {}, # all announced donations by id\n",
    "    'inventory': inventory, # available (undistributed) resources\n",
    "    'agents': agents, # agents with their inventories; includes solvers\n",
    "    'donation_receipts': {}, # proofs of donation by request id\n",
    "    'strategies': {}, # selected donation(s) by request id\n",
    "    'solvers': solvers,\n",
    "    'solvers_by_economy': solvers_by_economy,\n",
    "    'requests_pool': {},\n",
    "    'receipts_pool': {},\n",
    "    'requests_fulfilled_pool': {},\n",
    "    'finalized_donations_pool': [],\n",
    "    'metrics': {\n",
    "        'throughput': 0, # total requests solved\n",
    "        'average_latency': 0.0, # average request resolution over timesteps\n",
    "        'decentralization_index': decentralization_indices, # concentration, distribution, and decentralization indices by resource\n",
    "        'cumulative_idling_capacity': idling_capacity_overall, # idle / available (the lower the better as resources are used; however, open requests must be considered for discussion)\n",
    "        'cumulative_idling_capacity_by_resource': idling_capacity_by_resource,\n",
    "        'poa': None, # TBD\n",
    "        'waste_rate': None, # TBD\n",
    "        'waste_units': None, # TBD\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Initial State: {initial_state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTEPS = 20\n",
    "\n",
    "# TODO add system setup params\n",
    "system_params = {\n",
    "    'need_threshold': [0.8]\n",
    "}\n",
    "\n",
    "sim_config = config_sim({\n",
    "    \"N\": 1, # Monte Carlo runs\n",
    "    \"T\": range(TIMESTEPS), # timesteps\n",
    "    \"M\": system_params # parameters\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del configs[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment()\n",
    "\n",
    "experiment.append_configs(\n",
    "    initial_state = initial_state,\n",
    "    partial_state_update_blocks = PSUBs,\n",
    "    sim_configs = sim_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_context = ExecutionContext()\n",
    "simulation = Executor(exec_context=exec_context, configs=configs)\n",
    "raw_result, tensor_field, sessions = simulation.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: cadCAD notebooks\n",
    "\n",
    "df = pd.DataFrame(raw_result)\n",
    "\n",
    "# Insert cadCAD parameters for each configuration into DataFrame\n",
    "for config in configs:\n",
    "    # Get parameters from configuration\n",
    "    parameters = config.sim_config['M']\n",
    "    # Get subset index from configuration\n",
    "    subset_index = config.subset_id\n",
    "    \n",
    "    # For each parameter key value pair\n",
    "    for (key, value) in parameters.items():\n",
    "        # Select all DataFrame indices where subset == subset_index\n",
    "        dataframe_indices = df.eval(f'subset == {subset_index}')\n",
    "        # Assign each parameter key value pair to the DataFrame for the corresponding subset\n",
    "        df.loc[dataframe_indices, key] = value\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "# TODO refactor and move to module\n",
    "\n",
    "def get_requests_stats(run_start, run_end):\n",
    "\n",
    "    total_requests = []\n",
    "    total_fulfilled_requests = []\n",
    "    requests_stats_prc = {}\n",
    "\n",
    "    for i in range(run_start, run_end + 1, 5):\n",
    "        \n",
    "        total_requests.append(len(df['requests'][i]))\n",
    "\n",
    "        count_fulfilled = 0\n",
    "        for request_id, request in df['requests'][i].items():\n",
    "            if request.state == REQUEST_FULFILLED:\n",
    "                count_fulfilled += 1\n",
    "\n",
    "        total_fulfilled_requests.append(count_fulfilled)\n",
    "\n",
    "    requests_stats = defaultdict(lambda: [])\n",
    "\n",
    "    for i in range(run_start, run_end + 1, 5):\n",
    "        requests_stats[\"total_requests\"].append(len(df['requests'][i]))\n",
    "\n",
    "        count_fulfilled = 0\n",
    "        count_main = 0\n",
    "        count_subrequests = 0\n",
    "        count_main_fulfilled = 0\n",
    "        count_subrequests_fulfilled = 0\n",
    "\n",
    "        for request_id, request in df['requests'][i].items():\n",
    "            if request.rtype == \"atomic\" or request.rtype == \"complex\":\n",
    "                count_main += 1 \n",
    "\n",
    "                if request.state == REQUEST_FULFILLED:\n",
    "                    count_main_fulfilled += 1\n",
    "                    count_fulfilled += 1\n",
    "\n",
    "            else:\n",
    "                count_subrequests += 1\n",
    "\n",
    "                if request.state == REQUEST_FULFILLED:\n",
    "                    count_subrequests_fulfilled += 1\n",
    "                    count_fulfilled += 1\n",
    "\n",
    "        requests_stats[\"fulfilled_requests\"].append(count_fulfilled)\n",
    "        requests_stats[\"fulfilled_main_requests\"].append(count_main_fulfilled)\n",
    "        requests_stats[\"fulfilled_subrequests\"].append(count_subrequests_fulfilled)\n",
    "        requests_stats[\"total_main_requests\"].append(count_main)\n",
    "        requests_stats[\"total_subrequests\"].append(count_subrequests)\n",
    "\n",
    "    requests_stats_prc[\"total_requests_prc\"] = 100.0\n",
    "    requests_stats_prc[\"fulfilled_requests_of_total_prc\"] = round(requests_stats[\"fulfilled_requests\"][-1] * 100.0 / requests_stats[\"total_requests\"][-1], 2)\n",
    "    requests_stats_prc[\"total_main_requests_prc\"] = round(requests_stats[\"total_main_requests\"][-1] * 100.0 / requests_stats[\"total_requests\"][-1], 2)\n",
    "    requests_stats_prc[\"total_subrequests_prc\"] = round(requests_stats[\"total_subrequests\"][-1] * 100.0 / requests_stats[\"total_requests\"][-1], 2)\n",
    "    requests_stats_prc[\"fulfilled_main_requests_prc\"] = round(requests_stats[\"fulfilled_main_requests\"][-1] * 100.0 / requests_stats[\"fulfilled_requests\"][-1], 2)\n",
    "    requests_stats_prc[\"fulfilled_subrequests_prc\"] = round(requests_stats[\"fulfilled_subrequests\"][-1] * 100.0 / requests_stats[\"fulfilled_requests\"][-1], 2)\n",
    "\n",
    "\n",
    "    return requests_stats, requests_stats_prc\n",
    "\n",
    "def get_donations_stats(run_end):\n",
    "\n",
    "    donations_data = defaultdict(lambda: 0)\n",
    "\n",
    "    for donation_id, donation in df['donation_responses'][run_end].items():\n",
    "        if donation.state == DONATION_SUBMITTED:\n",
    "            donations_data[\"submitted\"] += 1\n",
    "        \n",
    "        if donation.state == DONATION_SELECTED:\n",
    "            donations_data[\"submitted\"] += 1\n",
    "            donations_data[\"selected\"] += 1\n",
    "\n",
    "        if donation.state == DONATION_FINALIZED:\n",
    "            donations_data[\"submitted\"] += 1\n",
    "            donations_data[\"selected\"] += 1\n",
    "            donations_data[\"finalized\"] += 1\n",
    "\n",
    "    donations_data_prc = {\n",
    "        \"submitted\": 100.0,\n",
    "        \"selected\": round(donations_data[\"selected\"] * 100.0 / donations_data[\"submitted\"], 2),\n",
    "        \"finalized\": round(donations_data[\"finalized\"] * 100.0 / donations_data[\"submitted\"], 2)\n",
    "    }\n",
    "\n",
    "    return donations_data, donations_data_prc\n",
    "\n",
    "# source: chatGPT\n",
    "def dict_to_csv(f, d):\n",
    "    with open(f, 'a', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=d.keys())\n",
    "        \n",
    "        if file.tell() == 0:\n",
    "            writer.writeheader()\n",
    "\n",
    "        writer.writerow(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_by_run = defaultdict(lambda: {})\n",
    "\n",
    "# generate data for analysis\n",
    "starts = [0]\n",
    "ends = [TIMESTEPS * len(PSUBs)]\n",
    "\n",
    "for i in range(len(starts)):\n",
    "    requests_stats, requests_stats_prc = get_requests_stats(starts[i], ends[i])\n",
    "    donations_stats, donations_stats_prc = get_donations_stats(ends[i])\n",
    "\n",
    "    stats_by_run[i][\"request_stats\"] = requests_stats\n",
    "    stats_by_run[i][\"requests_stats_prc\"] = requests_stats_prc\n",
    "    stats_by_run[i][\"donations_stats\"] = donations_stats\n",
    "    stats_by_run[i][\"donations_stats_prc\"] = donations_stats_prc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "\n",
    "all_data = defaultdict(lambda: {})\n",
    "\n",
    "for run in stats_by_run.keys():\n",
    "    all_data[run] = defaultdict(lambda: 0.0)\n",
    "    all_data[run][\"sim_id\"] = run\n",
    "\n",
    "    for stat_type, value in stats_by_run[run][\"request_stats\"].items():\n",
    "        all_data[run][stat_type] = value[-1]\n",
    "\n",
    "\n",
    "    for stat_type, value in stats_by_run[run][\"requests_stats_prc\"].items():\n",
    "        all_data[run][stat_type] = value\n",
    "\n",
    "    for stat_type, value in stats_by_run[run][\"donations_stats\"].items():\n",
    "        all_data[run][stat_type + \"_count\"] = value\n",
    "        all_data[run][stat_type + \"_prc\"] = stats_by_run[run][\"donations_stats_prc\"][stat_type]\n",
    "\n",
    "\n",
    "    all_data[run][\"latency\"] = df['metrics'][ends[run]]['latency']\n",
    "    all_data[run][\"throughput\"] = df['metrics'][ends[run]]['throughput']\n",
    "\n",
    "    # sim params\n",
    "    all_data[run][\"need_threshold\"] = system_params[\"need_threshold\"][0]\n",
    "\n",
    "    for key in initial_state_params.keys():\n",
    "        all_data[run][key] = initial_state_params[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save simulation results\n",
    "for run in stats_by_run.keys():\n",
    "    dict_to_csv('path/to/file.csv', all_data[run])\n",
    "\n",
    "# save selected analysis data\n",
    "dict_to_csv('path/to/file.csv', all_data[0])\n",
    "df.to_csv('path/to/file.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_total_req = np.array(requests_stats[\"total_requests\"])\n",
    "data_main_req = np.array(requests_stats[\"total_main_requests\"])\n",
    "data_sub_req = np.array(requests_stats[\"total_subrequests\"])\n",
    "data_total_fulfilled_req = np.array(requests_stats[\"fulfilled_requests\"])\n",
    "data_fulfilled_main_req = np.array(requests_stats[\"fulfilled_main_requests\"])\n",
    "data_fulfilled_sub_req = np.array(requests_stats[\"fulfilled_subrequests\"])\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "\n",
    "times = np.array([i for i in range(TIMESTEPS + 1)])\n",
    "\n",
    "plt.plot(times, data_total_req, label='total requests', linestyle='-', color=\"orange\")\n",
    "plt.plot(times, data_main_req, label='total main requests', linestyle='--', color=\"orange\")\n",
    "plt.plot(times, data_sub_req, label='total subrequests', linestyle=':', color=\"orange\")\n",
    "plt.plot(times, data_total_fulfilled_req, label='fulfilled requests', linestyle='-', color=\"green\")\n",
    "plt.plot(times, data_fulfilled_main_req, label='fulfilled main requests', linestyle='--', color=\"green\")\n",
    "plt.plot(times, data_fulfilled_sub_req, label='fulfilled subrequests', linestyle=':', color=\"green\")\n",
    "\n",
    "\n",
    "plt.xlabel('timestep')\n",
    "plt.ylabel('requests')\n",
    "plt.xticks(times)\n",
    "plt.legend()\n",
    "plt.title(\"Exploratory Analysis: submitted vs fulfilled requests (raw count)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Resource decentralization at beginning of system (first 30 resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources_decentralization = defaultdict(lambda: {})\n",
    "\n",
    "owners = defaultdict(lambda: 0)\n",
    "\n",
    "for agent_id, agent in agents.items():\n",
    "    for resource_id in agent.inventory.stock.keys():\n",
    "        owners[resource_id] += 1\n",
    "\n",
    "for resource_id in decentralization_indices.keys():\n",
    "    \n",
    "    resources_decentralization[resource_id][\"owners\"] = owners[resource_id]\n",
    "    resources_decentralization[resource_id][\"min_c\"] = decentralization_indices[resource_id][\"min_c\"]\n",
    "    resources_decentralization[resource_id][\"max_c\"] = decentralization_indices[resource_id][\"max_c\"]\n",
    "    resources_decentralization[resource_id][\"dec_index\"] = decentralization_indices[resource_id][\"decentralization_index\"]\n",
    "    resources_decentralization[resource_id][\"con_index\"] = decentralization_indices[resource_id][\"concentration_index\"]\n",
    "    resources_decentralization[resource_id][\"distr_index\"] = decentralization_indices[resource_id][\"distribution_index\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = []\n",
    "xticks = []\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(16, 5))\n",
    "\n",
    "counter = 1\n",
    "\n",
    "for resource_id in resources_decentralization.keys():\n",
    "    if counter > 30: # stop display after the first 30 resources\n",
    "        break\n",
    "\n",
    "    dis.append(resources_decentralization[resource_id][\"dec_index\"])\n",
    "    \n",
    "    p1 = [counter, resources_decentralization[resource_id][\"max_c\"] - resources_decentralization[resource_id][\"min_c\"]]\n",
    "    p2 = [counter, 0]\n",
    "    \n",
    "    ax1.plot([p1[0], p2[0]], [p1[1], p2[1]], color=\"blue\", marker='_', linestyle=\"-\", alpha=0.5)\n",
    "\n",
    "    ax1.bar(counter, resources_decentralization[resource_id]['distr_index'], color=\"gray\", alpha=0.3, width=0.5)\n",
    "\n",
    "    xticks.append(counter)\n",
    "    counter += 1\n",
    "\n",
    "ax1.scatter(xticks, dis, marker=\"o\", color=\"green\")\n",
    "ax1.set_ylabel(\"concentration index (ownership range) \\n resource owners (as % of total)\\n decentralization index\")\n",
    "ax1.set_xticks(xticks)\n",
    "ax1.set_xticklabels([\"r_\"+str(i - 1)+\"\" for i in xticks])\n",
    "ax1.set_yticklabels([0.0, 0.2, 0.4, 0.6, 0.8, 1.0], color=\"green\")\n",
    "\n",
    "ax1.set_xlabel(\"resource id\")\n",
    "\n",
    "fig.tight_layout() \n",
    "plt.title(\"initial state: resource decentralization (30 resources)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources_decentralization_final = defaultdict(lambda: {})\n",
    "\n",
    "owners_final = defaultdict(lambda: 0)\n",
    "\n",
    "final_step = TIMESTEPS * len(PSUBs)\n",
    "for agent_id, agent in df['agents'][final_step].items():\n",
    "    for resource_id in agent.inventory.stock.keys():\n",
    "        owners_final[resource_id] += 1\n",
    "\n",
    "for resource_id in df['metrics'][final_step]['decentralization_index'].keys():\n",
    "    \n",
    "    resources_decentralization_final[resource_id][\"owners\"] = owners_final[resource_id]\n",
    "    resources_decentralization_final[resource_id][\"min_c\"] = df['metrics'][final_step]['decentralization_index'][resource_id][\"min_c\"]\n",
    "    resources_decentralization_final[resource_id][\"max_c\"] = df['metrics'][final_step]['decentralization_index'][resource_id][\"max_c\"]\n",
    "    resources_decentralization_final[resource_id][\"dec_index\"] = df['metrics'][final_step]['decentralization_index'][resource_id][\"decentralization_index\"]\n",
    "    resources_decentralization_final[resource_id][\"con_index\"] = df['metrics'][final_step]['decentralization_index'][resource_id][\"concentration_index\"]\n",
    "    resources_decentralization_final[resource_id][\"distr_index\"] = df['metrics'][final_step]['decentralization_index'][resource_id][\"distribution_index\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis = []\n",
    "xticks = []\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(16, 5))\n",
    "\n",
    "counter = 1\n",
    "for resource_id in resources_decentralization_final.keys():\n",
    "    if counter > 30: # stop display after the first 30 resources\n",
    "        break\n",
    "\n",
    "    dis.append(resources_decentralization_final[resource_id][\"dec_index\"])\n",
    "    \n",
    "    p1 = [counter, resources_decentralization_final[resource_id][\"max_c\"] - resources_decentralization_final[resource_id][\"min_c\"]]\n",
    "    p2 = [counter, 0]\n",
    "    ax1.plot([p1[0], p2[0]], [p1[1], p2[1]], color=\"blue\", marker='_', linestyle=\"-\", alpha=0.5)\n",
    "\n",
    "    ax1.bar(counter, resources_decentralization_final[resource_id]['distr_index'], color=\"gray\", alpha=0.3, width=0.5)\n",
    "\n",
    "    xticks.append(counter)\n",
    "    counter += 1\n",
    "\n",
    "ax1.scatter(xticks, dis, marker=\"o\", color=\"green\")\n",
    "ax1.set_ylabel(\"concentration index (ownership range) \\n resource owners (as % of total)\\n decentralization index\")\n",
    "ax1.set_xticks(xticks)\n",
    "ax1.set_xticklabels([\"r_\"+str(i - 1)+\"\" for i in xticks])\n",
    "ax1.set_yticklabels([0.0, 0.2, 0.4, 0.6, 0.8, 1.0], color=\"green\")\n",
    "\n",
    "ax1.set_xlabel(\"resource id\")\n",
    "\n",
    "\n",
    "\n",
    "fig.tight_layout() \n",
    "plt.title(\"final state: resource decentralization (30 resources)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Resource decentralization evolution (first 10 resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources_decentralization_by_state = defaultdict(lambda: {})\n",
    "\n",
    "for state_id in range(TIMESTEPS):\n",
    "    \n",
    "    # owners for a given state\n",
    "    owners = defaultdict(lambda: 0)\n",
    "\n",
    "    for agent_id, agent in df['agents'][state_id * 5].items():\n",
    "        for resource_id in agent.inventory.stock.keys():\n",
    "            owners[resource_id] += 1\n",
    "\n",
    "    st = \"state_\" + str(state_id)\n",
    "\n",
    "    resources_decentralization_by_state[st] = defaultdict(lambda: {})\n",
    "    decentralization_indices = df['metrics'][state_id * 5]['decentralization_index']\n",
    "\n",
    "    for resource_id in decentralization_indices.keys():\n",
    "        \n",
    "        resources_decentralization_by_state[st][resource_id][\"owners\"] = owners[resource_id]\n",
    "        resources_decentralization_by_state[st][resource_id][\"min_c\"] = decentralization_indices[resource_id][\"min_c\"]\n",
    "        resources_decentralization_by_state[st][resource_id][\"max_c\"] = decentralization_indices[resource_id][\"max_c\"]\n",
    "        resources_decentralization_by_state[st][resource_id][\"dec_index\"] = decentralization_indices[resource_id][\"decentralization_index\"]\n",
    "        resources_decentralization_by_state[st][resource_id][\"con_index\"] = decentralization_indices[resource_id][\"concentration_index\"]\n",
    "        resources_decentralization_by_state[st][resource_id][\"distr_index\"] = decentralization_indices[resource_id][\"distribution_index\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resource_0 evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rid = \"resource_0\"\n",
    "\n",
    "dis = []\n",
    "xticks = []\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "for state_id in range(TIMESTEPS):\n",
    "\n",
    "    st = \"state_\" + str(state_id)\n",
    "\n",
    "    dis.append(resources_decentralization_by_state[st][rid][\"dec_index\"])\n",
    "    \n",
    "\n",
    "    p1 = [state_id, resources_decentralization_by_state[st][rid][\"max_c\"] - resources_decentralization_by_state[st][rid][\"min_c\"]]\n",
    "    p2 = [state_id, 0]\n",
    "    plt.plot([p1[0], p2[0]], [p1[1], p2[1]], color=\"blue\", marker='_', linestyle=\"-\", alpha=0.5)\n",
    "    plt.bar(state_id, resources_decentralization_by_state[st][rid]['distr_index'], color=\"gray\", alpha=0.3, width=0.5)\n",
    "\n",
    "    xticks.append(state_id)\n",
    " \n",
    "plt.scatter(xticks, dis, marker=\"o\", color=\"green\")# linestyle=\"-\"\n",
    "plt.ylabel(\"resource ownership range \\n resource owners (as % of total)\\n decentralization index\")\n",
    "plt.xticks(xticks)\n",
    "plt.xlabel(\"state id\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = 0\n",
    "dis = defaultdict(lambda: [])\n",
    "xticks = []\n",
    "rids = list(resources_decentralization_by_state[\"state_0\"].keys())[:10]\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "\n",
    "for state_id in range(TIMESTEPS):\n",
    "\n",
    "    st = \"state_\" + str(state_id)\n",
    "\n",
    "    for rid in rids:\n",
    "        dis[rid].append(resources_decentralization_by_state[st][rid][\"dec_index\"])\n",
    "    \n",
    "    xticks.append(state_id)\n",
    "\n",
    "ctr, ctr2 = 0, 1\n",
    "\n",
    "colors = {}\n",
    "linestyles = {}\n",
    "\n",
    "for rid in dis.keys():\n",
    "    c = (2 * ctr, 0.3 * ctr, 0.1 + 2 * ctr)\n",
    "\n",
    "    colors[rid] = c\n",
    "\n",
    "    l = \"-\"\n",
    "    if ctr2 % 2 == 0:\n",
    "        l = \":\"\n",
    "    if ctr2 % 3 == 0:\n",
    "        l = \"--\"\n",
    "    \n",
    "    linestyles[rid] = l\n",
    "    ctr += 0.05\n",
    "    ctr2 += 1\n",
    "\n",
    "for rid in dis.keys():\n",
    "\n",
    "    plt.plot(xticks, dis[rid], linestyle=linestyles[rid], color=colors[rid])\n",
    "\n",
    "\n",
    "plt.ylabel(\"decentralization index\")\n",
    "plt.xticks(xticks)\n",
    "plt.xlabel(\"state id\")\n",
    "plt.legend(rids, loc=1)\n",
    "plt.title(\"Exploratory Analysis: decentralization index evolution (10 resources)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Decentralization-conscious agents' donations contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_id = TIMESTEPS * len(PSUBs)\n",
    "\n",
    "agents_distribution = defaultdict(lambda: 0)\n",
    "\n",
    "for agent_id, agent in df['agents'][state_id].items():\n",
    "    agents_distribution[agent.atype] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donations_by_agent_type = defaultdict(lambda: 0)\n",
    "finalized_donations_by_agent_type = defaultdict(lambda: 0)\n",
    "selected_donations_by_agent_type = defaultdict(lambda: 0)\n",
    "\n",
    "for donation_id, donation in df['donation_responses'][state_id].items():\n",
    "    donations_by_agent_type[df['agents'][state_id][donation.donor].atype] += 1\n",
    "\n",
    "    if donation.state == DONATION_FINALIZED:\n",
    "        finalized_donations_by_agent_type[df['agents'][state_id][donation.donor].atype] += 1\n",
    "\n",
    "donor_receipts_by_agent_type = defaultdict(lambda: 0)\n",
    "\n",
    "for receipt_id, receipt in df['donation_receipts'][state_id].items():\n",
    "    if receipt.rtype == RECEIPT_DONOR:\n",
    "        donor_receipts_by_agent_type[df['agents'][state_id][receipt.agent_id].atype] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_stats = {\n",
    "    \"fulfilled_requests\": 0,\n",
    "    \"fulfilled_main_requests\": 0,\n",
    "    \"fulfilled_subrequests\": 0,\n",
    "    \"total_requests\": len(df['requests'][state_id]),\n",
    "    \"total_main_requests\": 0,\n",
    "    \"total_subrequests\": 0\n",
    "}\n",
    "\n",
    "for request_id, request in df['requests'][state_id].items():\n",
    "    if request.rtype == \"atomic\" or request.rtype == \"complex\":\n",
    "            requests_stats[\"total_main_requests\"] += 1 \n",
    "\n",
    "            if request.state == REQUEST_FULFILLED:\n",
    "                requests_stats[\"fulfilled_main_requests\"] += 1\n",
    "    else:\n",
    "        requests_stats[\"total_subrequests\"] += 1\n",
    "\n",
    "        if request.state == REQUEST_FULFILLED:\n",
    "                requests_stats[\"fulfilled_subrequests\"] += 1\n",
    "\n",
    "requests_stats[\"fulfilled_requests\"] = requests_stats[\"fulfilled_main_requests\"] + requests_stats[\"fulfilled_subrequests\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# donor distribution\n",
    "donation_distribution_data_by_agent = defaultdict(lambda: {})\n",
    "\n",
    "# agent distribution\n",
    "total_agents = sum(agents_distribution.values())\n",
    "total_donations = sum(donations_by_agent_type.values())\n",
    "total_finalized_donations = sum(finalized_donations_by_agent_type.values())\n",
    "total_donor_receipts = sum(donor_receipts_by_agent_type.values())\n",
    "\n",
    "\n",
    "for atype in agents_distribution.keys():\n",
    "    donation_distribution_data_by_agent[atype][\"prc_of_agents\"] = round(agents_distribution[atype] * 100.0 / total_agents, 2)\n",
    "    donation_distribution_data_by_agent[atype][\"prc_of_donation_responses\"] = round(donations_by_agent_type[atype] * 100.0 / total_donations, 2)\n",
    "    donation_distribution_data_by_agent[atype][\"prc_of_finalized_donations\"] = round(finalized_donations_by_agent_type[atype] * 100.0 / total_finalized_donations, 2)\n",
    "    donation_distribution_data_by_agent[atype][\"prc_of_donor_receipts\"] = round(donor_receipts_by_agent_type[atype] * 100.0 / total_donor_receipts, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Donations by economy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donations_database = {}\n",
    "\n",
    "for donation_id, donation in df['donation_responses'][state_id].items():\n",
    "    if donation.state == DONATION_FINALIZED:\n",
    "        donations_database[donation_id] = {\n",
    "            \"from\": donation.donor,\n",
    "            \"to\": df['requests'][state_id][donation.request_id].requestor,\n",
    "            \"econ_out\": donation.economy_id_from,\n",
    "            \"econ_in\": donation.economy_id_to,\n",
    "            \"resource_id\": df['requests'][state_id][donation.request_id].resource_id,\n",
    "            \"quantity\": donation.quantity\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "donations_database = {}\n",
    "\n",
    "for donation_id, donation in df['donation_responses'][state_id].items():\n",
    "    if donation.state == DONATION_FINALIZED:\n",
    "        donations_database[donation_id] = {\n",
    "            \"from\": donation.donor,\n",
    "            \"to\": df['requests'][state_id][donation.request_id].requestor,\n",
    "            \"econ_out\": donation.economy_id_from,\n",
    "            \"econ_in\": donation.economy_id_to,\n",
    "            \"resource_id\": df['requests'][state_id][donation.request_id].resource_id,\n",
    "            \"quantity\": donation.quantity\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.MultiDiGraph()\n",
    "H = nx.MultiDiGraph()\n",
    "\n",
    "H.add_nodes_from(G.nodes)\n",
    "\n",
    "for economy in economies:\n",
    "    total_balance = 0\n",
    "    G.add_node(economy, balance=total_balance)\n",
    "\n",
    "for donation_id, transaction in donations_database.items():\n",
    "    \n",
    "    source = transaction['econ_out']\n",
    "    destination = transaction['econ_in']\n",
    "    amount = transaction['quantity']\n",
    "    \n",
    "    if source != destination:\n",
    "        # update nodes' balances\n",
    "        G.nodes[source]['balance'] -= amount\n",
    "        G.nodes[destination]['balance'] += amount\n",
    "        \n",
    "        # add tx as edge\n",
    "        G.add_edge(source, destination, amount=amount)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help with only drawing specific edges to help longitudinal analysis\n",
    "# https://stackoverflow.com/questions/74406226/draw-specific-edges-in-graph-in-networkx\n",
    "# help wtih animations\n",
    "# https://stackoverflow.com/questions/43445103/inline-animations-in-jupyter\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "\n",
    "nodes_balances = nx.get_node_attributes(G, 'balance')\n",
    "node_labels = {\n",
    "    node: node.split(\"_\")[1]\n",
    "    for node, value\n",
    "    in nodes_balances.items()\n",
    "}\n",
    "\n",
    "# node sizes\n",
    "sizes = [700 for i in range(len(economies))]\n",
    "\n",
    "pos = nx.spring_layout(G, seed=5)\n",
    "\n",
    "def animate(t):\n",
    "    plt.cla()\n",
    "\n",
    "    nx.draw_networkx_nodes(G,\n",
    "        pos, \n",
    "        node_size=sizes, \n",
    "        alpha=1,\n",
    "        node_color=\"darkgreen\")\n",
    "        \n",
    "    nx.draw_networkx_edges(H, pos, \n",
    "            alpha=0.05,\n",
    "            width=3, \n",
    "            edge_color=\"gray\")\n",
    "    \n",
    "    H.add_edge('econ_3', 'econ_4')\n",
    "\n",
    "    donations_database = {}\n",
    "\n",
    "    for donation_id, donation in df['donation_responses'][t * 5].items():\n",
    "        if donation.state == DONATION_FINALIZED:\n",
    "            donations_database[donation_id] = {\n",
    "                \"econ_out\": donation.economy_id_from,\n",
    "                \"econ_in\": donation.economy_id_to,\n",
    "            }\n",
    "\n",
    "    for donation_id, transaction in donations_database.items():\n",
    "    \n",
    "        source = transaction['econ_out']\n",
    "        destination = transaction['econ_in']\n",
    "        H.add_edge(source, destination, amount=amount)\n",
    "\n",
    "    nx.draw_networkx_labels(G, pos, labels=node_labels, font_color=\"white\", font_size=20)\n",
    "\n",
    "anim = matplotlib.animation.FuncAnimation(fig, animate, frames=TIMESTEPS)\n",
    "\n",
    "f = r\"../animation.gif\" \n",
    "writergif = matplotlib.animation.PillowWriter(fps=1) \n",
    "anim.save(f, writer=writergif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure().clear()\n",
    "plt.close()\n",
    "plt.cla()\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
